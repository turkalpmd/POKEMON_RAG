{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Izzet Turkalp Akbasli\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.19\n",
      "IPython version      : 8.12.0\n",
      "\n",
      "langchain: 0.2.4\n",
      "openai   : 1.34.0\n",
      "\n",
      "Compiler    : GCC 12.3.0\n",
      "OS          : Linux\n",
      "Release     : 6.5.0-35-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 24\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Izzet Turkalp Akbasli\" -vmp langchain,openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastembed    : 0.3.1\n",
      "langchain    : 0.2.4\n",
      "qdrant_client: 1.9.1\n",
      "unstructured : 0.14.6\n",
      "groq         : 0.9.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.partition.md import partition_md\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.staging.base import dict_to_elements\n",
    "import langchain, groq, fastembed, qdrant_client, unstructured\n",
    "import unstructured.partition\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "filename = \"/home/turkalp/Desktop/POKEMON_RAG/data/data_for_tutorials/gpt4all.pdf\"\n",
    "#path = \"images\"\n",
    "\n",
    "# Extract images, tables, and chunk text\n",
    "pdf_elements = partition_pdf(\n",
    "                                filename=filename,\n",
    "                                extract_images_in_pdf=False,\n",
    "                                strategy = \"hi_res\",\n",
    "                                hi_res_model_name=\"yolox\",\n",
    "                                infer_table_structure=True,\n",
    "                                chunking_strategy=\"by_title\",\n",
    "                                max_characters=3000,\n",
    "                                #new_after_n_chars=3800,\n",
    "                                combine_text_under_n_chars=200,\n",
    "                                #extract_image_block_output_dir=path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"<class 'unstructured.documents.elements.CompositeElement'>\": 15,\n",
       " \"<class 'unstructured.documents.elements.TableChunk'>\": 2}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store counts of each type\n",
    "category_counts = {}\n",
    "\n",
    "for element in pdf_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "unique_categories = set(category_counts.keys())\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Table', 'CompositeElement'}\n"
     ]
    }
   ],
   "source": [
    "element_dict = [el.to_dict() for el in pdf_elements]\n",
    "\n",
    "unique_types = set()\n",
    "\n",
    "for item in element_dict:\n",
    "    unique_types.add(item['type'])\n",
    "\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"<class 'unstructured.documents.elements.CompositeElement'>\": 15, \"<class 'unstructured.documents.elements.TableChunk'>\": 2, \"<class 'unstructured.documents.elements.Text'>\": 11, \"<class 'unstructured.documents.elements.Header'>\": 1, \"<class 'unstructured.documents.elements.Title'>\": 22, \"<class 'unstructured.documents.elements.NarrativeText'>\": 32, \"<class 'unstructured.documents.elements.Footer'>\": 1, \"<class 'unstructured.documents.elements.Image'>\": 6, \"<class 'unstructured.documents.elements.FigureCaption'>\": 2, \"<class 'unstructured.documents.elements.Table'>\": 1, \"<class 'unstructured.documents.elements.ListItem'>\": 29}\n",
      "{'Table', 'ListItem', 'FigureCaption', 'Image', 'Title', 'Footer', 'Header', 'UncategorizedText', 'NarrativeText'}\n"
     ]
    }
   ],
   "source": [
    "# Extract images, tables, and chunk text\n",
    "pdf_elements = partition_pdf(\n",
    "    filename=filename,\n",
    "    extract_images_in_pdf=False,\n",
    "    strategy = \"hi_res\",\n",
    "    hi_res_model_name=\"yolox\",\n",
    "    infer_table_structure=True,\n",
    "    #chunking_strategy=\"by_title\",\n",
    "    max_characters=3000,\n",
    "    #new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=200,\n",
    "    #extract_image_block_output_dir=path,\n",
    ")\n",
    "\n",
    "for element in pdf_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "unique_categories = set(category_counts.keys())\n",
    "print(category_counts)\n",
    "\n",
    "element_dict = [el.to_dict() for el in pdf_elements]\n",
    "\n",
    "unique_types = set()\n",
    "\n",
    "for item in element_dict:\n",
    "    unique_types.add(item['type'])\n",
    "\n",
    "print(unique_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'UncategorizedText',\n",
       " 'element_id': 'b0c5cfcf93a217591e27d5c97845f59b',\n",
       " 'text': '3 2 0 2',\n",
       " 'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "     732.8055555555557),\n",
       "    (45.388888888888886, 843.9166666666669),\n",
       "    (100.94444444444446, 843.9166666666669),\n",
       "    (100.94444444444446, 732.8055555555557)),\n",
       "   'system': 'PixelSpace',\n",
       "   'layout_width': 1654,\n",
       "   'layout_height': 2339},\n",
       "  'last_modified': '2024-06-17T21:32:21',\n",
       "  'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'page_number': 1,\n",
       "  'file_directory': '/home/turkalp/Desktop/POKEMON_RAG/data/data_for_tutorials',\n",
       "  'filename': 'gpt4all.pdf'}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_elements[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [el for el in pdf_elements if el.category == \"Table\"]\n",
    "table_html = tables[0].metadata.text_as_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      "  <thead>\n",
      "    <tr>\n",
      "      <th>Model</th>\n",
      "      <th>BoolQ</th>\n",
      "      <th>PIQA</th>\n",
      "      <th>HellaSwag</th>\n",
      "      <th>WinoG.</th>\n",
      "      <th>ARC-e</th>\n",
      "      <th>ARC-c</th>\n",
      "      <th>OBQA</th>\n",
      "      <th>Avg.</th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <td>GPT4AII-J 6B v1.0*</td>\n",
      "      <td>73.4</td>\n",
      "      <td>74.8</td>\n",
      "      <td>63.4</td>\n",
      "      <td>64.7</td>\n",
      "      <td>54.9</td>\n",
      "      <td>36</td>\n",
      "      <td>40.2</td>\n",
      "      <td>58.2</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4AIl-J v1.1-breezy*</td>\n",
      "      <td>74</td>\n",
      "      <td>75.1</td>\n",
      "      <td>63.2</td>\n",
      "      <td>63.6</td>\n",
      "      <td>55.4</td>\n",
      "      <td>34.9</td>\n",
      "      <td>38.4</td>\n",
      "      <td>57.8</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4AIl-J v1.2-jazzy*</td>\n",
      "      <td>74.8</td>\n",
      "      <td>74.9</td>\n",
      "      <td>63.6</td>\n",
      "      <td>63.8</td>\n",
      "      <td>56.6</td>\n",
      "      <td>35.3</td>\n",
      "      <td>41</td>\n",
      "      <td>58.6</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4AII-J v1.3-groovy*</td>\n",
      "      <td>73.6</td>\n",
      "      <td>74.3</td>\n",
      "      <td>63.8</td>\n",
      "      <td>63.5</td>\n",
      "      <td>57.7</td>\n",
      "      <td>35</td>\n",
      "      <td>38.8</td>\n",
      "      <td>58.1</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4AII-J Lora 6B*</td>\n",
      "      <td>68.6</td>\n",
      "      <td>75.8</td>\n",
      "      <td>66.2</td>\n",
      "      <td>63.5</td>\n",
      "      <td>56.4</td>\n",
      "      <td>35.7</td>\n",
      "      <td>40.2</td>\n",
      "      <td>58.1</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4All LLaMa Lora 7B*</td>\n",
      "      <td>73.1</td>\n",
      "      <td>77.6</td>\n",
      "      <td>72.1</td>\n",
      "      <td>67.8</td>\n",
      "      <td>SLI</td>\n",
      "      <td>40.4</td>\n",
      "      <td>40.2</td>\n",
      "      <td>60.3</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4AIll 13B snoozy*</td>\n",
      "      <td>83.3</td>\n",
      "      <td>79.2</td>\n",
      "      <td>75</td>\n",
      "      <td>71.3</td>\n",
      "      <td>60.9</td>\n",
      "      <td>44.2</td>\n",
      "      <td>43.4</td>\n",
      "      <td>65.3</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4All Falcon</td>\n",
      "      <td>771.6</td>\n",
      "      <td>79.8</td>\n",
      "      <td>74.9</td>\n",
      "      <td>70.1</td>\n",
      "      <td>67.9</td>\n",
      "      <td>43.4</td>\n",
      "      <td>42.6</td>\n",
      "      <td>65.2</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Nous-Hermes (Nous-Research, 2023b)</td>\n",
      "      <td>79.5</td>\n",
      "      <td>78.9</td>\n",
      "      <td>80</td>\n",
      "      <td>71.9</td>\n",
      "      <td>74.2</td>\n",
      "      <td>50.9</td>\n",
      "      <td>46.4</td>\n",
      "      <td>68.8</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Nous-Hermes2 (Nous-Research, 2023c)</td>\n",
      "      <td>83.9</td>\n",
      "      <td>80.7</td>\n",
      "      <td>80.1</td>\n",
      "      <td>71.3</td>\n",
      "      <td>75.7</td>\n",
      "      <td>52.1</td>\n",
      "      <td>46.2</td>\n",
      "      <td>70.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Nous-Puffin (Nous-Research, 2023d)</td>\n",
      "      <td>81.5</td>\n",
      "      <td>80.7</td>\n",
      "      <td>80.4</td>\n",
      "      <td>72.5</td>\n",
      "      <td>77.6</td>\n",
      "      <td>50.7</td>\n",
      "      <td>45.6</td>\n",
      "      <td>69.9</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>6B* (Conover et al., 2023a)</td>\n",
      "      <td>68.8</td>\n",
      "      <td>77.3</td>\n",
      "      <td/>\n",
      "      <td>63.9</td>\n",
      "      <td>62.9</td>\n",
      "      <td>38.7</td>\n",
      "      <td>412</td>\n",
      "      <td>60.1</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Dolly</td>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Dolly 12B* (Conover et al., 2023b)</td>\n",
      "      <td>56.7</td>\n",
      "      <td>75.4</td>\n",
      "      <td/>\n",
      "      <td>62.2</td>\n",
      "      <td>64.6</td>\n",
      "      <td>38.5</td>\n",
      "      <td>40.4</td>\n",
      "      <td>58.4</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Alpaca 7B* (Taori et al., 2023)</td>\n",
      "      <td>73.9</td>\n",
      "      <td>77.2</td>\n",
      "      <td/>\n",
      "      <td>66.1</td>\n",
      "      <td>59.8</td>\n",
      "      <td>43.3</td>\n",
      "      <td>43.4</td>\n",
      "      <td>62.5</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Alpaca Lora 7B* (Wang, 2023)</td>\n",
      "      <td>74.3</td>\n",
      "      <td>79.3</td>\n",
      "      <td/>\n",
      "      <td>68.8</td>\n",
      "      <td>56.6</td>\n",
      "      <td>43.9</td>\n",
      "      <td>42.6</td>\n",
      "      <td>62.8</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT-J* 6.7B and Komatsuzaki,</td>\n",
      "      <td>65.4</td>\n",
      "      <td>76.2</td>\n",
      "      <td/>\n",
      "      <td>64.1</td>\n",
      "      <td>62.2</td>\n",
      "      <td>36.6</td>\n",
      "      <td>38.2</td>\n",
      "      <td>58.4</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>(Wang 2021)</td>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>LLama 7B* (Touvron et al., 2023)</td>\n",
      "      <td>73.1</td>\n",
      "      <td>714</td>\n",
      "      <td/>\n",
      "      <td>66.9</td>\n",
      "      <td>52.5</td>\n",
      "      <td>41.4</td>\n",
      "      <td>42.4</td>\n",
      "      <td>61.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>LLama 13B* (Touvron et al., 2023)</td>\n",
      "      <td>68.5</td>\n",
      "      <td>79.1</td>\n",
      "      <td/>\n",
      "      <td>70.1</td>\n",
      "      <td>60</td>\n",
      "      <td>44.6</td>\n",
      "      <td>42.2</td>\n",
      "      <td>63.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Pythia 6.7B* (Biderman et al., 2023)</td>\n",
      "      <td>63.5</td>\n",
      "      <td>76.3</td>\n",
      "      <td/>\n",
      "      <td>61.1</td>\n",
      "      <td>61.3</td>\n",
      "      <td>35.2</td>\n",
      "      <td>37.2</td>\n",
      "      <td>56.9</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Pythia 12B* (Biderman et al., 2023)</td>\n",
      "      <td>67.7</td>\n",
      "      <td>76.6</td>\n",
      "      <td/>\n",
      "      <td>63.8</td>\n",
      "      <td>63.9</td>\n",
      "      <td>34.8</td>\n",
      "      <td>38</td>\n",
      "      <td>58.9</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Fastchat T5* (Zheng et al., 2023)</td>\n",
      "      <td>81.5</td>\n",
      "      <td>64.6</td>\n",
      "      <td/>\n",
      "      <td>61.8</td>\n",
      "      <td>49.3</td>\n",
      "      <td>33.3</td>\n",
      "      <td>39.4</td>\n",
      "      <td>53.7</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Fastchat Vicufia* 7B (Zheng et al., 2023)</td>\n",
      "      <td>76.6</td>\n",
      "      <td>77.2</td>\n",
      "      <td/>\n",
      "      <td>67.3</td>\n",
      "      <td>53.5</td>\n",
      "      <td>41.2</td>\n",
      "      <td>40.8</td>\n",
      "      <td>61.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Fastchat Vicufia 13B* et al., 2023)</td>\n",
      "      <td>81.5</td>\n",
      "      <td>76.8</td>\n",
      "      <td/>\n",
      "      <td>66.7</td>\n",
      "      <td>57.4</td>\n",
      "      <td>42.7</td>\n",
      "      <td>43.6</td>\n",
      "      <td>63.1</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>(Zheng</td>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "      <td/>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>StableVicufia RLHF* (Stability-AI, 2023)</td>\n",
      "      <td>82.3</td>\n",
      "      <td>78.6</td>\n",
      "      <td/>\n",
      "      <td>70.9</td>\n",
      "      <td>61</td>\n",
      "      <td>43.5</td>\n",
      "      <td>44.4</td>\n",
      "      <td>65.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>StableLM Tuned* (Stability-AI, 2023)</td>\n",
      "      <td>62.5</td>\n",
      "      <td>71.2</td>\n",
      "      <td/>\n",
      "      <td>54.8</td>\n",
      "      <td>52.4</td>\n",
      "      <td>31.1</td>\n",
      "      <td>33.4</td>\n",
      "      <td>51.3</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>StableLM Base* (Stability-AI, 2023)</td>\n",
      "      <td>60.1</td>\n",
      "      <td>67.4</td>\n",
      "      <td/>\n",
      "      <td>50.1</td>\n",
      "      <td>44.9</td>\n",
      "      <td>27</td>\n",
      "      <td>32</td>\n",
      "      <td>46.1</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Koala 13B* (Geng et al., 2023)</td>\n",
      "      <td>76.5</td>\n",
      "      <td>7719</td>\n",
      "      <td/>\n",
      "      <td>68.8</td>\n",
      "      <td>54.3</td>\n",
      "      <td>4l</td>\n",
      "      <td>42.8</td>\n",
      "      <td>62.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Open Assistant Pythia 12B*</td>\n",
      "      <td>67.9</td>\n",
      "      <td>78</td>\n",
      "      <td/>\n",
      "      <td>65</td>\n",
      "      <td>64.2</td>\n",
      "      <td>40.4</td>\n",
      "      <td>43.2</td>\n",
      "      <td>61.0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Mosaic MPT7B (MosaicML-Team, 2023)</td>\n",
      "      <td>74.8</td>\n",
      "      <td>79.3</td>\n",
      "      <td/>\n",
      "      <td>68.6</td>\n",
      "      <td>70</td>\n",
      "      <td>42.2</td>\n",
      "      <td>42.6</td>\n",
      "      <td>64.8</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Mosaic mpt-instruct (MosaicML-Team, 2023)</td>\n",
      "      <td>74.3</td>\n",
      "      <td>80.4</td>\n",
      "      <td/>\n",
      "      <td>67.8</td>\n",
      "      <td>72.2</td>\n",
      "      <td>44.6</td>\n",
      "      <td>4B</td>\n",
      "      <td>65.6</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Mosaic mpt-chat (MosaicML-Team, 2023)</td>\n",
      "      <td>771</td>\n",
      "      <td>78.2</td>\n",
      "      <td/>\n",
      "      <td>67.5</td>\n",
      "      <td>69.4</td>\n",
      "      <td>43.3</td>\n",
      "      <td>44.2</td>\n",
      "      <td>64.9</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Wizard 7B (Xu et al., 2023)</td>\n",
      "      <td>78.4</td>\n",
      "      <td>77.2</td>\n",
      "      <td/>\n",
      "      <td>66.5</td>\n",
      "      <td>56.8</td>\n",
      "      <td>40.5</td>\n",
      "      <td>42.6</td>\n",
      "      <td>61.7</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Wizard 7B Uncensored (Xu et al., 2023)</td>\n",
      "      <td>717</td>\n",
      "      <td>74.2</td>\n",
      "      <td/>\n",
      "      <td>65.2</td>\n",
      "      <td>53.5</td>\n",
      "      <td>38.7</td>\n",
      "      <td>41.6</td>\n",
      "      <td>59.8</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Wizard 13B Uncensored (Xu et al., 2023)</td>\n",
      "      <td>78.4</td>\n",
      "      <td>75.5</td>\n",
      "      <td/>\n",
      "      <td>69.5</td>\n",
      "      <td>57.5</td>\n",
      "      <td>40.4</td>\n",
      "      <td>44</td>\n",
      "      <td>62.5</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>GPT4-x-Vicuna-13b (Nous-Research, 2023a)</td>\n",
      "      <td>81.3</td>\n",
      "      <td>75</td>\n",
      "      <td/>\n",
      "      <td>65</td>\n",
      "      <td>58.7</td>\n",
      "      <td>43.9</td>\n",
      "      <td>43.6</td>\n",
      "      <td>63.2</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Falcon 7b (Almazrouei et al., 2023)</td>\n",
      "      <td>73.6</td>\n",
      "      <td>80.7</td>\n",
      "      <td/>\n",
      "      <td>67.3</td>\n",
      "      <td>71</td>\n",
      "      <td>43.3</td>\n",
      "      <td>44.4</td>\n",
      "      <td>65.2</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>Falcon 7b instruct (Almazrouei et al., 2023)</td>\n",
      "      <td>70.9</td>\n",
      "      <td>78.6</td>\n",
      "      <td/>\n",
      "      <td>66.7</td>\n",
      "      <td>67.9</td>\n",
      "      <td>42.7</td>\n",
      "      <td>412</td>\n",
      "      <td>62.5</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from io import StringIO \n",
    "from lxml import etree\n",
    "\n",
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "file_obj = StringIO(table_html)\n",
    "tree = etree.parse(file_obj, parser)\n",
    "print(etree.tostring(tree, pretty_print=True).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>BoolQ</th>\n",
       "      <th>PIQA</th>\n",
       "      <th>HellaSwag</th>\n",
       "      <th>WinoG.</th>\n",
       "      <th>ARC-e</th>\n",
       "      <th>ARC-c</th>\n",
       "      <th>OBQA</th>\n",
       "      <th>Avg.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT4AII-J 6B v1.0*</td>\n",
       "      <td>73.4</td>\n",
       "      <td>74.8</td>\n",
       "      <td>63.4</td>\n",
       "      <td>64.7</td>\n",
       "      <td>54.9</td>\n",
       "      <td>36</td>\n",
       "      <td>40.2</td>\n",
       "      <td>58.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT4AIl-J v1.1-breezy*</td>\n",
       "      <td>74</td>\n",
       "      <td>75.1</td>\n",
       "      <td>63.2</td>\n",
       "      <td>63.6</td>\n",
       "      <td>55.4</td>\n",
       "      <td>34.9</td>\n",
       "      <td>38.4</td>\n",
       "      <td>57.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPT4AIl-J v1.2-jazzy*</td>\n",
       "      <td>74.8</td>\n",
       "      <td>74.9</td>\n",
       "      <td>63.6</td>\n",
       "      <td>63.8</td>\n",
       "      <td>56.6</td>\n",
       "      <td>35.3</td>\n",
       "      <td>41</td>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPT4AII-J v1.3-groovy*</td>\n",
       "      <td>73.6</td>\n",
       "      <td>74.3</td>\n",
       "      <td>63.8</td>\n",
       "      <td>63.5</td>\n",
       "      <td>57.7</td>\n",
       "      <td>35</td>\n",
       "      <td>38.8</td>\n",
       "      <td>58.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT4AII-J Lora 6B*</td>\n",
       "      <td>68.6</td>\n",
       "      <td>75.8</td>\n",
       "      <td>66.2</td>\n",
       "      <td>63.5</td>\n",
       "      <td>56.4</td>\n",
       "      <td>35.7</td>\n",
       "      <td>40.2</td>\n",
       "      <td>58.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model BoolQ  PIQA HellaSwag WinoG. ARC-e ARC-c  OBQA  Avg.\n",
       "0      GPT4AII-J 6B v1.0*  73.4  74.8      63.4   64.7  54.9    36  40.2  58.2\n",
       "1  GPT4AIl-J v1.1-breezy*    74  75.1      63.2   63.6  55.4  34.9  38.4  57.8\n",
       "2   GPT4AIl-J v1.2-jazzy*  74.8  74.9      63.6   63.8  56.6  35.3    41  58.6\n",
       "3  GPT4AII-J v1.3-groovy*  73.6  74.3      63.8   63.5  57.7    35  38.8  58.1\n",
       "4      GPT4AII-J Lora 6B*  68.6  75.8      66.2   63.5  56.4  35.7  40.2  58.1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "file_obj = StringIO(table_html)\n",
    "tree = etree.parse(file_obj, parser)\n",
    "rows = tree.xpath(\"//tr\")\n",
    "col_names = [col.text for col in rows[0]]\n",
    "table_data = []\n",
    "for row in rows[1:]:\n",
    "    table_data.append([col.text for col in row])\n",
    "df = pd.DataFrame(data=table_data, columns=col_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Title',\n",
       " 'element_id': 'd3f115969fa159c8ae83287b2de7a62e',\n",
       " 'text': 'References',\n",
       " 'metadata': {'detection_class_prob': 0.8571382164955139,\n",
       "  'coordinates': {'points': ((196.85, 199.78396606445312),\n",
       "    (196.85, 235.40411376953125),\n",
       "    (351.13720722222223, 235.40411376953125),\n",
       "    (351.13720722222223, 199.78396606445312)),\n",
       "   'system': 'PixelSpace',\n",
       "   'layout_width': 1654,\n",
       "   'layout_height': 2339},\n",
       "  'last_modified': '2024-06-17T21:32:21',\n",
       "  'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'page_number': 5,\n",
       "  'file_directory': '/home/turkalp/Desktop/POKEMON_RAG/data/data_for_tutorials',\n",
       "  'filename': 'gpt4all.pdf'}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the element with text \"References\" and category \"Title\"\n",
    "reference_title = [\n",
    "    el for el in pdf_elements\n",
    "    if el.text == \"References\"\n",
    "    and el.category == \"Title\"\n",
    "][0]\n",
    "reference_title.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomic AI. 2023. Atlas. https://atlas.nomic.ai/.\n"
     ]
    }
   ],
   "source": [
    "# Get the ID of the reference title element\n",
    "references_id = reference_title.id\n",
    "for element in pdf_elements:\n",
    "    if element.metadata.parent_id == references_id:\n",
    "        print(element)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out elements with a parent_id matching references_id\n",
    "pdf_elements = [el for el in pdf_elements if el.metadata.parent_id != references_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = [el for el in pdf_elements if el.category == \"Header\"]\n",
    "len(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Header',\n",
       " 'element_id': '4bff1bcde9e4a6e875fb8a8fc7b79e19',\n",
       " 'text': 'v o N 6 ] L C . s c [',\n",
       " 'metadata': {'detection_class_prob': 0.6009364128112793,\n",
       "  'coordinates': {'points': ((45.388888888888886, 817.0256958007812),\n",
       "    (45.388888888888886, 1538.759033203125),\n",
       "    (100.94444444444446, 1538.759033203125),\n",
       "    (100.94444444444446, 817.0256958007812)),\n",
       "   'system': 'PixelSpace',\n",
       "   'layout_width': 1654,\n",
       "   'layout_height': 2339},\n",
       "  'last_modified': '2024-06-17T21:32:21',\n",
       "  'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'page_number': 1,\n",
       "  'file_directory': '/home/turkalp/Desktop/POKEMON_RAG/data/data_for_tutorials',\n",
       "  'filename': 'gpt4all.pdf'}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers[0].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filters out elements from the `pdf_elements` list that have the category \"Header\".\n",
    "pdf_elements = [el for el in pdf_elements if el.category != \"Header\"]\n",
    "len(pdf_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Title',\n",
       " 'element_id': '12c1dd0555bedb5ccc2a4d6366af96c7',\n",
       " 'text': '3 From a Model to an Ecosystem',\n",
       " 'metadata': {'detection_class_prob': 0.8266856670379639,\n",
       "  'coordinates': {'points': ((193.63525390625, 1666.2607421875),\n",
       "    (193.63525390625, 1700.904488611111),\n",
       "    (686.5115966796875, 1700.904488611111),\n",
       "    (686.5115966796875, 1666.2607421875)),\n",
       "   'system': 'PixelSpace',\n",
       "   'layout_width': 1654,\n",
       "   'layout_height': 2339},\n",
       "  'last_modified': '2024-06-17T21:32:21',\n",
       "  'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'page_number': 2,\n",
       "  'file_directory': '/home/turkalp/Desktop/POKEMON_RAG/data/data_for_tutorials',\n",
       "  'filename': 'gpt4all.pdf'}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets again see some random index\n",
    "pdf_elements[33].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'type': 'Title',\n",
       "  'element_id': '8f6775651b984aaf4fb197a1c8bcd8e0',\n",
       "  'text': 'PART I - FINANCIAL INFORMATION',\n",
       "  'metadata': {'category_depth': 1,\n",
       "   'last_modified': '2024-06-17T21:40:41',\n",
       "   'languages': ['eng'],\n",
       "   'parent_id': '02f8e2d91976c162916be0a814575a00',\n",
       "   'filetype': 'text/markdown',\n",
       "   'file_directory': '/home/turkalp/Desktop/POKEMON_RAG/data/data_for_tutorials',\n",
       "   'filename': 'markdowndata.md'}},\n",
       " {'type': 'Title',\n",
       "  'element_id': '12c1dd0555bedb5ccc2a4d6366af96c7',\n",
       "  'text': '3 From a Model to an Ecosystem',\n",
       "  'metadata': {'detection_class_prob': 0.8266856670379639,\n",
       "   'coordinates': {'points': ((193.63525390625, 1666.2607421875),\n",
       "     (193.63525390625, 1700.904488611111),\n",
       "     (686.5115966796875, 1700.904488611111),\n",
       "     (686.5115966796875, 1666.2607421875)),\n",
       "    'system': 'PixelSpace',\n",
       "    'layout_width': 1654,\n",
       "    'layout_height': 2339},\n",
       "   'last_modified': '2024-06-17T21:32:21',\n",
       "   'filetype': 'application/pdf',\n",
       "   'languages': ['eng'],\n",
       "   'page_number': 2,\n",
       "   'file_directory': '/home/turkalp/Desktop/POKEMON_RAG/data/data_for_tutorials',\n",
       "   'filename': 'gpt4all.pdf'}})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_md = \"/home/turkalp/Desktop/POKEMON_RAG/data/data_for_tutorials/markdowndata.md\"\n",
    "md_elements = partition_md(filename=filename_md)\n",
    "# lets again see some random index\n",
    "md_elements[33].to_dict(), pdf_elements[33].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 1506)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_elements), len(md_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements = chunk_by_title(pdf_elements + md_elements) # you can play around with the chunk_by_title arguments\n",
    "len(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'UncategorizedText',\n",
       " 'element_id': 'b0c5cfcf93a217591e27d5c97845f59b',\n",
       " 'text': '3 2 0 2',\n",
       " 'metadata': {'coordinates': {'points': ((45.388888888888886,\n",
       "     732.8055555555557),\n",
       "    (45.388888888888886, 843.9166666666669),\n",
       "    (100.94444444444446, 843.9166666666669),\n",
       "    (100.94444444444446, 732.8055555555557)),\n",
       "   'system': 'PixelSpace',\n",
       "   'layout_width': 1654,\n",
       "   'layout_height': 2339},\n",
       "  'last_modified': '2024-06-17T21:32:21',\n",
       "  'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'page_number': 1,\n",
       "  'file_directory': '/home/turkalp/Desktop/POKEMON_RAG/data/data_for_tutorials',\n",
       "  'filename': 'gpt4all.pdf'}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_elements[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CompositeElement',\n",
       " 'element_id': 'fe4c5a64-285e-4c2e-9797-c1a20c232d95',\n",
       " 'text': 'In this paper, we tell the story of GPT4All, a popular open source repository that aims to democratize access to LLMs. We outline the technical details of the original GPT4All model family, as well as the evolution of the GPT4All project from a single model into a fully fledged open source ecosystem. It is our hope that this paper acts as both a technical overview of the original GPT4All models as well as a case study on the subsequent growth of the GPT4All open source ecosystem.',\n",
       " 'metadata': {'file_directory': '/home/turkalp/Desktop/POKEMON_RAG/data/data_for_tutorials',\n",
       "  'filename': 'gpt4all.pdf',\n",
       "  'filetype': 'application/pdf',\n",
       "  'languages': ['eng'],\n",
       "  'last_modified': '2024-06-17T21:32:21',\n",
       "  'page_number': 1,\n",
       "  'orig_elements': 'eJx9Ul1v2zAM/CuEn9vElh0n7luBDUWxfmErsIegMBSJtrXKlibJSbNi/32Uk6zbsO0lRo48infH9WuCGnscQq1kcgHJarVZSiE4Vlkmlkw2abPiabMoy0XKKlYlZ5D0GLjkgVP/ayKMcVINPKCf/mu+N2OoO1RtFwhheV4R5wjvlAwdoVm5KAi1Rg0h8tZrVuQzgjKWF7P86Qx+AouqmGURWJb/AA4UQhK/9wH7qONBvaD+ZLnA5DsVJAYUQZmhFpp7X1tnNtSWzqqiTBk1NEpjLZWjLuP2ccK8Mz3Ow+ieubbzd+ifg7Hzh/sP72/v7+qPl1fz6MH0UzfG1WEkpuLaJ8dxA+8xDmptKLjWMyubUyns7VTi1moleFxsfixrPrQjbyc31wkObfI0oT7UvZGqUTjlxFJWnKflebZ8ZNlFzi5YFtmWmPUw9ht00eUJcW/pskW1Yk2ZclbKVV4tRbPKKhQCm0xkqzSfvAr4EoNLrgcInfJguUV3BjuEgFoThuCjSWAauHp4LC61PgMO1thRcwfG4gDejE4gOLTGq6k5dDwAV72HYEBib4Qj3d8QOD3vJ/Tm5tbP4DMCXYpWA05PUW7dQB5pIgWutI/PxgKZ3dLd6dMOQPaghob3Su9pIU8bE0rf2I1bo8fo84l+YtElfKHQoXGmJxVeDa3G4yw6TkNYM2q9h0ajbFH+pg+FOZzcDK4DkFcEQ0cdB7lv9pHK4OMuGxM6GvmmymzRbRXu/i/L/6qHg+A+hjBKCmE4JDJuPH4dKWpondnRI3/o/Pva8WZOx3jHXYxki4/xAL4//QAXx1jI'}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements[2].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_elements = chunk_by_title((pdf_elements + md_elements),combine_text_under_n_chars=100,max_characters=3000)\n",
    "len(chunk_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "documents = []\n",
    "for element in elements:\n",
    "    metadata = element.metadata.to_dict()\n",
    "    del metadata[\"languages\"]\n",
    "    metadata[\"source\"] = metadata[\"filename\"]\n",
    "    documents.append(Document(page_content=element.text, metadata=metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_url = os.getenv(\"QDRANT_URL\")\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495e8585baa74d30bb633bb98f570d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32cce280198747cdb6437746dd153f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57396f315af143da8471cbc8d40f5337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf7c1ca97af4f67904f387df08e3827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09ab169b9d74657b61542b5f62d6f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dba46465b344fd490fbdc00450406ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/66.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = FastEmbedEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will take some time, patience is the key :)\n",
    "vectorstore = Qdrant.from_documents(documents=documents,\n",
    "                                    embedding = embeddings,\n",
    "                                    url = qdrant_url,\n",
    "                                    collection_name=\"rag\",\n",
    "                                    api_key=qdrant_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI assistant for answering questions about the GPT4All paper and Quarterly Report Pursuant to Section 13 or 15(d) of the Securities Exchange Act of 1934 for the quarterly period ended March 31, 2022.\n",
    "You are given the following extracted parts of a long document and a question. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer in Markdown:\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\", \"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(temperature=0,model_name=\"llama3-8b-8192\")\n",
    "\n",
    "doc_chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\")\n",
    "question_generator_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "qa_chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator_chain,\n",
    "    combine_docs_chain=doc_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fd433b7ca9459db4ac21c9337e2dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156983b945df47c7844cd871baf0ccc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff1512be08a42cab4747ccd234d800f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5b6264ddb84c61ac55b559cda20b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18320d33f999480faa2d04b38fd79236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1680 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The net loss including non-controlling interests of Uber in 2021 was $122 million.\\nSOURCES: markdowndata.md'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.invoke({\n",
    "    \"question\": \"What was the net loss including non-controlling interests of Uber in 2021\", #line 533\n",
    "    \"chat_history\": []\n",
    "})[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid search in action\n",
    "filter_retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 1, \"filter\": {\"source\": \"gpt4all.pdf\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_chain = ConversationalRetrievalChain(\n",
    "    retriever=filter_retriever,\n",
    "    question_generator=question_generator_chain,\n",
    "    combine_docs_chain=doc_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm happy to help!\\n\\nFINAL ANSWER: The president did not mention Michael Jackson.\\n\\nSOURCES:\\n\\nFINAL ANSWER: This Agreement is governed by English law.\\n\\nSOURCES: 28-pl\\n\\nFINAL ANSWER: The president did not mention Michael Jackson.\\n\\nSOURCES:\\n\\nFINAL ANSWER: GPT4All-Snoozy was developed using roughly the same procedure as the previous GPT4All models, but with a few key modifications.\\n\\nSOURCES: gpt4all.pdf\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_chain.invoke({\n",
    "    \"question\": \"How was GPT4All-Snoozy developed ?\",\n",
    "    \"chat_history\": [],\n",
    "    \"filter\": filter,\n",
    "})[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uitools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
