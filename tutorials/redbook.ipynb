{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Izzet Turkalp Akbasli\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.19\n",
      "IPython version      : 8.12.0\n",
      "\n",
      "langchain: 0.2.5\n",
      "openai   : 1.34.0\n",
      "\n",
      "Compiler    : GCC 12.3.0\n",
      "OS          : Linux\n",
      "Release     : 6.5.0-35-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 24\n",
      "Architecture: 64bit\n",
      "\n",
      "unstructured : 0.14.6\n",
      "fastembed    : 0.3.1\n",
      "langchain    : 0.2.5\n",
      "qdrant_client: 1.9.1\n",
      "groq         : 0.9.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.partition.md import partition_md\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.staging.base import dict_to_elements\n",
    "import langchain, groq, fastembed, qdrant_client, unstructured\n",
    "import unstructured.partition\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Izzet Turkalp Akbasli\" -vmp langchain,openai\n",
    "\n",
    "# Suppress all warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display version information for imported libraries\n",
    "%watermark --iversions\n",
    "\n",
    "# Specify the path to your PDF file\n",
    "filename = \"/home/turkalp/Desktop/POKEMON_RAG/data/data_for_tutorials/redbook.pdf\"\n",
    "#path = \"images\"  # Uncomment and specify path if you want to extract images\n",
    "\n",
    "# Extract images, tables, and chunk text from the PDF\n",
    "pdf_elements = partition_pdf(\n",
    "    filename=filename,                                    # Path to the PDF file\n",
    "    strategy=\"hi_res\",                                    # Strategy for extraction, \"hi_res\" for high resolution\n",
    "    extract_images_in_pdf=False,                          # Set to True to extract images from PDF\n",
    "    #extract_image_block_types=[\"Image\", \"Table\"],         # optional    \n",
    "    hi_res_model_name=\"yolox\",                            # Model name for high resolution extraction\n",
    "    infer_table_structure=False,                           # Set to True to infer the structure of tables\n",
    "    chunking_strategy=\"by_title\",                         # Strategy to chunk text, here by titles\n",
    "    max_characters=3000,                                  # Maximum characters per chunk\n",
    "    #new_after_n_chars=2000,                              # Uncomment to start new chunk after specified characters\n",
    "    combine_text_under_n_chars=200,                       # Combine text chunks if under specified characters\n",
    "    #extract_image_block_output_dir=path,                 # Uncomment and specify path to save extracted image blocks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"<class 'unstructured.documents.elements.CompositeElement'>\": 2460, \"<class 'unstructured.documents.elements.Table'>\": 284, \"<class 'unstructured.documents.elements.TableChunk'>\": 12}\n",
      "{'CompositeElement', 'Table'}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store counts of each type of PDF element\n",
    "category_counts = {}\n",
    "\n",
    "# Iterate through each element in the extracted PDF elements\n",
    "for element in pdf_elements:\n",
    "    # Get the type of the element as a string\n",
    "    category = str(type(element))\n",
    "    # Increment the count if the category already exists in the dictionary\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    # Add the category to the dictionary with an initial count of 1 if it does not exist\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Create a set of unique categories from the keys of the category_counts dictionary\n",
    "unique_categories = set(category_counts.keys())\n",
    "\n",
    "# Output the category counts\n",
    "print(category_counts)\n",
    "\n",
    "# Convert each PDF element to a dictionary and store in a list\n",
    "element_dict = [el.to_dict() for el in pdf_elements]\n",
    "\n",
    "# Create a set to store unique types of elements\n",
    "unique_types = set()\n",
    "\n",
    "# Iterate through each dictionary element\n",
    "for item in element_dict:\n",
    "    # Add the 'type' of each element to the unique_types set\n",
    "    unique_types.add(item['type'])\n",
    "\n",
    "# Output the set of unique types\n",
    "print(unique_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2045\n",
      "10384\n"
     ]
    }
   ],
   "source": [
    "# Import the chunk_by_title function from the unstructured.chunking.title module\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "\n",
    "# Chunk the PDF elements based on their titles with specific arguments\n",
    "chunk_elements = chunk_by_title(\n",
    "    pdf_elements,                   # List of elements to be chunked\n",
    "    combine_text_under_n_chars=200,  # Combine text elements that are under 20 characters\n",
    "    max_characters=3000             # Maximum number of characters allowed in a single chunk\n",
    ")\n",
    "\n",
    "# Print the number of chunked elements\n",
    "print(len(chunk_elements))\n",
    "\n",
    "# Chunk the PDF elements based on their titles with default arguments\n",
    "elements = chunk_by_title(pdf_elements)  # You can modify the arguments to see different chunking results\n",
    "\n",
    "# Print the number of elements after chunking with default arguments\n",
    "print(len(elements))\n",
    "\n",
    "# Argument Explanations:\n",
    "# - pdf_elements: This is the list of elements extracted from the PDF.\n",
    "# - combine_text_under_n_chars: This argument specifies the minimum number of characters for individual text elements. \n",
    "#   If a text element has fewer characters than this value, it will be combined with adjacent text elements until the total exceeds this value.\n",
    "# - max_characters: This sets the maximum number of characters for each chunk. If a chunk exceeds this limit, it will be split into smaller chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c43d938e1840a581a432797adfa225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991bd24a449b485aba14ede5ffe152dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1cd5a4fbe049ca95a7b0a351c88302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/66.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ee2114283e4020a9001f0643340c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ff935632b04e3f8fd3fe284d3c5fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04deedbe65448679ffd52fdf62cf710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()    \n",
    "\n",
    "# Get API keys and URLs from environment variables\n",
    "qdrant_url = os.getenv(\"QDRANT_URL\")\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialize an empty list to store document objects\n",
    "documents = []\n",
    "\n",
    "# Convert each element to a Document object with necessary metadata\n",
    "for element in elements:\n",
    "    # Convert element metadata to a dictionary\n",
    "    metadata = element.metadata.to_dict()\n",
    "    # Remove unnecessary 'languages' field from metadata\n",
    "    del metadata[\"languages\"]\n",
    "    # Set the source to the filename from metadata\n",
    "    metadata[\"source\"] = metadata[\"filename\"]\n",
    "    # Create a Document object with text content and metadata\n",
    "    documents.append(Document(page_content=element.text, metadata=metadata))\n",
    "\n",
    "# Initialize the FastEmbedEmbeddings object for embedding generation\n",
    "embeddings = FastEmbedEmbeddings()\n",
    "\n",
    "# Create a Qdrant vector store from the documents with embeddings\n",
    "# This step can take some time depending on the number of documents and their size\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=documents,          # List of documents to be indexed\n",
    "    embedding=embeddings,         # Embedding model to use\n",
    "    url=qdrant_url,               # URL for the Qdrant instance\n",
    "    collection_name=\"redbook\",        # Name of the Qdrant collection\n",
    "    api_key=qdrant_api_key        # API key for authentication\n",
    ")\n",
    "\n",
    "# Create a retriever object from the vector store for querying\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",     # Type of search to perform, here it's similarity search\n",
    "    search_kwargs={\"k\": 3}        # Additional search parameters, 'k' specifies the number of top results to return\n",
    ")\n",
    "\n",
    "# Argument Explanations:\n",
    "# - documents: A list of Document objects, each containing the text and metadata to be indexed.\n",
    "# - embedding: An instance of the embedding model used to convert text into vector representations.\n",
    "# - url: The URL of the Qdrant instance where the documents will be indexed.\n",
    "# - collection_name: The name of the collection in Qdrant where the documents will be stored.\n",
    "# - api_key: The API key for authenticating with the Qdrant instance.\n",
    "# - search_type: The type of search to perform, in this case, a similarity search to find similar documents.\n",
    "# - search_kwargs: Additional keyword arguments for the search, 'k' specifies the number of similar results to return.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2bbfb4f65754a758a5c0a8d083fedba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.vectorstores import Qdrant\n",
    "from langchain.embeddings import FastEmbedEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys and URLs from environment variables\n",
    "qdrant_url = os.getenv(\"QDRANT_URL\")\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Define the prompt template with an additional instruction\n",
    "template = \"\"\"You are a medical AI assistant specializing in infectious diseases and public health in children. You will receive excerpts from the Red Book along with related questions. \n",
    "Respond conversationally and in language similar to the question. If you're unsure of the answer, simply say, \"Hmm, I'm not sure,\" without attempting to provide incorrect information.\n",
    "Question: {input}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer in Markdown:\"\"\"\n",
    "\n",
    "# Create a PromptTemplate object with the defined template\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"input\", \"context\"])\n",
    "\n",
    "# Initialize the language model with specific parameters\n",
    "llm = ChatGroq(temperature=0, model_name=\"llama3-8b-8192\")\n",
    "\n",
    "# Create the document chain using the language model and the map-reduce strategy\n",
    "doc_chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "# Create embeddings using FastEmbedEmbeddings\n",
    "embeddings = FastEmbedEmbeddings()\n",
    "\n",
    "# Set up the Qdrant vector store to connect to the existing collection\n",
    "vectorstore = Qdrant.from_existing_collection(\n",
    "    embedding=embeddings,         # Embedding model to use\n",
    "    url=qdrant_url,               # URL for the Qdrant instance\n",
    "    collection_name=\"redbook\",        # Name of the existing Qdrant collection\n",
    "    api_key=qdrant_api_key,       # API key for authentication\n",
    "    path=None                     # Path to the existing collection, set to None if not needed\n",
    ")\n",
    "\n",
    "# Create a retriever object from the vector store for querying\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",     # Type of search to perform, here it's similarity search\n",
    "    search_kwargs={\"k\": 3}        # Additional search parameters, 'k' specifies the number of top results to return\n",
    ")\n",
    "\n",
    "# Create the history-aware retriever for context-aware querying\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm=RunnableSequence(prompt | llm),  # Language model sequence combining prompt and LLM\n",
    "    retriever=retriever,                 # Retriever for fetching relevant documents\n",
    "    prompt=prompt                        # Prompt template for the retriever\n",
    ")\n",
    "\n",
    "# Create the LLM chain for generating answers\n",
    "qa_chain = LLMChain(\n",
    "    llm=llm,                # Language model to use for generating answers\n",
    "    prompt=prompt           # Prompt template to guide the answer generation\n",
    ")\n",
    "\n",
    "# Argument Explanations:\n",
    "# - template: The text template that defines how the AI should respond, with placeholders for input and context.\n",
    "# - input_variables: Variables that will be replaced in the template (e.g., \"input\" and \"context\").\n",
    "# - temperature: Parameter for the language model that controls the randomness of the output (0 means deterministic).\n",
    "# - model_name: Specifies the model version of the language model.\n",
    "# - embedding: The embedding model used to convert text into vector representations.\n",
    "# - url: The URL of the Qdrant instance where the documents are stored.\n",
    "# - collection_name: The name of the existing collection in Qdrant.\n",
    "# - api_key: The API key for authenticating with the Qdrant instance.\n",
    "# - search_type: The type of search to perform, in this case, a similarity search to find similar documents.\n",
    "# - search_kwargs: Additional keyword arguments for the search, 'k' specifies the number of similar results to return.\n",
    "# - llm: The language model used for generating responses and integrated into various chains.\n",
    "# - retriever: The component used to fetch relevant documents from the vector store based on the query.\n",
    "# - prompt: The prompt template guiding the AI on how to respond to questions.\n",
    "# - RunnableSequence: Combines the prompt and the language model to create a sequence for the history-aware retriever.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**According to the Red Book, the recommended concentrations for maintaining safe swimming pool water are:**\n",
      "\n",
      "* Free chlorine: 1-3 parts per million (ppm)\n",
      "* Bromine: 3-5 ppm\n",
      "\n",
      "These concentrations are recommended to effectively kill bacteria, viruses, and other microorganisms that can cause illnesses in children.\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the recommended concentrations of free chlorine and bromine for maintaining safe swimming pool water?\"\n",
    "context = \"\"\"\n",
    "                The AAP Red Book is a comprehensive guide for infectious disease guidelines in pediatric practice, covering immunizations, diseases, antimicrobial therapy, and management strategies. \n",
    "                Ask for specific recommendations from the Red Book on infectious diseases anytime!\n",
    "           \"\"\"\n",
    "result = qa_chain.invoke({\"input\": question, \"context\": context, \"chat_history\": []})\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**According to the Red Book, children aged 5 to 14 are particularly susceptible to acute otitis externa (AOE) during recreational water activities because of the combination of factors that increase their risk.**\n",
      "\n",
      "The Red Book notes that this age group is more likely to engage in water activities, such as swimming and diving, which can lead to water entering the ear canal and increasing the risk of AOE. Additionally, children in this age group may not have developed the necessary ear canal anatomy to effectively prevent water from entering the ear, making them more prone to AOE.\n",
      "\n",
      "**It's also worth noting that the Red Book recommends that children with a history of AOE or ear canal abnormalities should avoid water activities that involve submerging their head underwater, and that parents and caregivers should take steps to prevent water from entering the ear canal, such as using earplugs or avoiding water activities when the ear canal is irritated or infected.**\n"
     ]
    }
   ],
   "source": [
    "question = \"Why are children aged 5 to 14 particularly susceptible to acute otitis externa (AOE) during recreational water activities?\"\n",
    "context = \"\"\"\n",
    "                The AAP Red Book is a comprehensive guide for infectious disease guidelines in pediatric practice, covering immunizations, diseases, antimicrobial therapy, and management strategies. \n",
    "                Ask for specific recommendations from the Red Book on infectious diseases anytime!\n",
    "           \"\"\"\n",
    "result = qa_chain.invoke({\"input\": question, \"context\": context, \"chat_history\": []})\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Typical symptoms of symptomatic intestinal amebiasis caused by Entamoeba histolytica in children include:**\n",
      "\n",
      "* Diarrhea, often bloody\n",
      "* Abdominal pain, tenderness, and cramping\n",
      "* Weight loss\n",
      "* Fever\n",
      "* Nausea and vomiting\n",
      "* Abdominal distension\n",
      "* Tenesmus (a feeling of rectal urgency)\n",
      "\n",
      "These symptoms can range from mild to severe and may be accompanied by other signs of infection, such as anemia, malnutrition, and growth retardation.\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the typical symptoms associated with symptomatic intestinal amebiasis caused by Entamoeba histolytica?\"\n",
    "context = \"\"\"\n",
    "                The AAP Red Book is a comprehensive guide for infectious disease guidelines in pediatric practice, covering immunizations, diseases, antimicrobial therapy, and management strategies. \n",
    "                Ask for specific recommendations from the Red Book on infectious diseases anytime!\n",
    "           \"\"\"\n",
    "result = qa_chain.invoke({\"input\": question, \"context\": context, \"chat_history\": []})\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Transmission and Prevalence of Entamoeba histolytica**\n",
      "\n",
      "According to the Red Book, Entamoeba histolytica is typically transmitted to humans through the fecal-oral route, where contaminated food, water, or surfaces are ingested. This can occur through direct contact with an infected person's feces, contaminated food or water, or through poor hygiene practices.\n",
      "\n",
      "The prevalence of Entamoeba histolytica infection varies greatly depending on factors such as geographic location, socioeconomic status, and access to clean water and sanitation. The Red Book notes that the infection is more common in developing countries with poor sanitation and hygiene practices, as well as in areas with high population density and crowding.\n",
      "\n",
      "In addition, the Red Book highlights that certain populations, such as children under the age of 5, are more susceptible to infection due to their immature immune systems and increased exposure to contaminated environments.\n",
      "\n",
      "Overall, it's essential to emphasize the importance of proper hygiene practices, such as frequent handwashing, and access to clean water and sanitation to prevent the transmission of Entamoeba histolytica and other infectious diseases.\n"
     ]
    }
   ],
   "source": [
    "question = \"How is Entamoeba histolytica transmitted to humans, and what factors influence its prevalence in different populations?\"\n",
    "context = \"\"\"\n",
    "                The AAP Red Book is a comprehensive guide for infectious disease guidelines in pediatric practice, covering immunizations, diseases, antimicrobial therapy, and management strategies. \n",
    "                Ask for specific recommendations from the Red Book on infectious diseases anytime!\n",
    "           \"\"\"\n",
    "result = qa_chain.invoke({\"input\": question, \"context\": context, \"chat_history\": []})\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uitools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
